# èµ·æ­¥ï¼ŒCS61A ç¬¬ä¸€ç« 

## å‡†å¤‡

ç¬¬ä¸€ç« å¯¹åº”è¯¾è¡¨å†…å‚è€ƒ Textbook ä¸º Ch1 çš„é¡¹ï¼Œé¢˜æº [CS61A 2024 Spring](https://cs61a.org/)ï¼Œä¸åŒæ—¶é—´é¢˜ç›®ç±»ä¼¼ã€‚

çŽ¯å¢ƒå¦‚ä½•è®¾ç½®å°±ä¸èµ˜è¿°äº†ï¼Œæœ¬ç³»åˆ—ä»…è®°å½•éƒ¨åˆ†æ€è€ƒä»¥åŠè¸©å‘çš„è§£å†³åŠžæ³• ðŸ™

## Lab 00

ç¬¬ä¸€æ¬¡ä½œä¸šï¼Œæ ¹æ®æç¤ºæˆ‘ä»¬éœ€è¦å…ˆä¸‹è½½æä¾›çš„ Stater Files ä¹Ÿå°±æ˜¯å…¥é—¨æ–‡ä»¶ï¼Œä¸‹è½½å®ŒæˆåŽå¾—åˆ°ä¸€ä¸ªåŽ‹ç¼©åŒ…ï¼Œè§£åŽ‹åŽæ‹–åˆ°ç¼–è¾‘å™¨é‡Œå³å¯ã€‚

è¿™æ˜¯æ­£å¸¸æµç¨‹ï¼Œä½†æˆ‘ä»¬æ˜¯å­¦ CS çš„ï¼Œè¦å­¦ç€ç”¨æ›´ nerd çš„æ–¹å¼æ¥åšã€‚

å¤åˆ¶ä¸‹è½½é“¾æŽ¥ï¼Œä½¿ç”¨ `wget` æ¥ä¸‹è½½æ–‡ä»¶ï¼Œç„¶åŽ `unzip` è§£åŽ‹ï¼š

```sh
wget https://cs61a.org/lab/lab00/lab00.zip
unzip lab00.zip
```

:::details å¦‚æžœä¸ç†Ÿæ‚‰è¿™äº›â€œå¥‡å¥‡æ€ªæ€ªâ€çš„å‘½ä»¤è¡Œå·¥å…·

å¯ä»¥å®‰è£…ä¸€ä¸ª [tldr](https://github.com/tldr-pages/tldr?tab=readme-ov-file#how-do-i-use-it) æ¥èŽ·çŸ¥å®ƒä»¬çš„ä½¿ç”¨æ–¹æ³•ï¼š

```sh
pip3 install tldr   # å®‰è£…
tldr wget           # ä½¿ç”¨
```

å®ƒä¼šè¿”å›žä¸€ä¸ªå¦‚ä¸‹çš„ç®€å•çš„ï¼ŒåŸºäºŽç¤ºä¾‹çš„æ‰‹å†Œï¼š

```md
> Download files from the Web.
> Supports HTTP, HTTPS, and FTP.
> More information: <https://www.gnu.org/software/wget>.

- Download the contents of a URL to a file (named "foo" in this case):

`wget {{https://example.com/foo}}`

- Download the contents of a URL to a file (named "bar" in this case):

`wget --output-document {{bar}} {{https://example.com/foo}}`

- Download a single web page and all its resources with 3-second intervals between requests (scripts, stylesheets, images, etc.):

`wget --page-requisites --convert-links --wait=3 {{https://example.com/somepage.html}}`

- Download all listed files within a directory and its sub-directories (does not download embedded page elements):

`wget --mirror --no-parent {{https://example.com/somepath/}}`

- Limit the download speed and the number of connection retries:

`wget --limit-rate={{300k}} --tries={{100}} {{https://example.com/somepath/}}`

- Download a file from an HTTP server using Basic Auth (also works for FTP):

`wget --user={{username}} --password={{password}} {{https://example.com}}`

- Continue an incomplete download:

`wget --continue {{https://example.com}}`

- Download all URLs stored in a text file to a specific directory:

`wget --directory-prefix {{path/to/directory}} --input-file {{URLs.txt}}`
```

:::

## HW 01

## Lab 01
